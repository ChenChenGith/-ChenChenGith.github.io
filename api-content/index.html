{"posts":[{"title":"关于OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.错误解决方法","content":"在一次Pycharm下debug时，报错： OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized. OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/. Process finished with exit code 3 网上查找相关解决方案，一般采用以下方式： import os os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;]=&quot;TRUE 但是这种方式治表不治里，在下一个项目运行中还有可能出行同样的问题。 搜索后看到web1和web2提供了一种根本性解决问题的方法。 本问题出现主要是因为torch包中包含了名为libiomp5md.dll的文件，与Anaconda环境中的同一个文件出现了某种冲突，所以需要删除一个。 在Anaconda文件夹下搜索，如下图，删除Anaconda包中libiomp5md.dll这个文件，即下图所选定的那个。 但如果是在某个python环境下，则需要删除的是该环境下的对应文件。 也就是： 如果在Anaconda的base环境下：删除*..\\Anaconda3\\Library\\bin\\libiomp5md.dll* 如果在某个env(例如名为work)下：删除*..\\Anaconda3\\envs\\work\\Library\\bin\\libiomp5md.dll* 问题解决 ","link":"https://ChenChenGith.github.io/post/guan-yu-omp-error-15-initializing-libiomp5mddll-but-found-libiomp5mddll-already-initializedcuo-wu-jie-jue-fang-fa/"},{"title":"Pytorch-LSTM学习心得","content":"近两个月的时间基本都是在与数据集和神经网络作斗争。至现在为止，终于算是在完成了数据规整和初步的LSTM-seq2seq网络的实现。并且开始维护了自己的代码项目。 在这里做一个阶段性的总结。 Pytorch-LSTM LSTM的模型构建及输入输出格式 考虑使用LSTM，或者说RNN的原因在于我所面临的输入数据长度是动态变化的，包括已知的车道中心线数量、长度，以及已知的自车和周车轨迹的数量和长度。而输出则是固定时域内的轨迹坐标。因此需要一个能够处理变长度输入的模型，因此选择RNN系列。 网络上有很多关于LSTM的模型构建，以及输入输出的参考。对于输入输出，我主要参考的包括： web_1 &lt;-引用了Pytorch官网说明 web_2 &lt;-其中的一个图很清晰的展示了输入输出 web_3 &lt;-双向传播隐层下的输入输出 其实刚刚开始看的时候，是很迷茫的。这与我自己比较差的数学功底（主要是线性代数）有关系，因此在开始的一段时间内并不能很好的理解所谓的input_size、hidden_size这些东西到底意味者什么，而我的input数据应该是何种shape才能够正确对应到这些网络参数。 大多数的网站都使用默认的XX_size这类的单词来说明，从python的编程角度来看，很容理解为某个变量的shape，但实际上带有size的大多是一个int值，所以一开始很难理解这个size值到底是指张量的哪个维度。 在不断地摸索过程中，我总结出一个规律，就是：所有的这些size大小指的都是数据或中间张量中最后一维向量的列数。而这里的最后一维，其实就是每一个独立数据点的特征向量。这是由于神经网络中都是线性变换，用到最多的就是矩阵乘法：A=WXA=WXA=WX，一个典型的感知器模型如下图所示： 假设输入XXX大小为(∗,∗,m)(*,*,m)(∗,∗,m)，即每个数据点的特征数量为mmm个（mmm维向量）；输出AAA的大小为(∗,∗,n)(*,*,n)(∗,∗,n)，即输出的每个数据点经过转换后的特征数量为nnn个（nnn维向量）；那么中间需要学习的权重矩阵WWW的大小就必需为(m,n)(m,n)(m,n)。当前大多数神经网络中的权重矩阵都是定大小的，所以这也就是为什么在定义LSTM等网络参数时必需关心输入size和输出size，这两者就定义了权重矩阵的shape。 而在做矩阵乘法的时候，除了最后一维外，其他的的维度是不变的，或者说与权重矩阵WWW无关的，所以就可以理解到，神经网络实际上每次变换都是针对最后一维（也就是特征向量）做变换的。 由于这种传递性质，如果需要更改前边维度的大小，就必须采用其他的方法，比如使用torch.tensor带有的view()方法来对维度大小做变换，又或者类似句子翻译问题中，通过构建一个解码器，构造一个预定义的SOS向量，作为解码器初始输入来控制解码器输出的前两维大小。 有了以上的认知，那么再可以回过头来看一下LSTM的模型构建、输入输出格式。 模型构建 Pytorch给出的LSTM模型构建方法为： net = nn.LSTM(input_size=3, hidden_size=10, num_layers=1, batch_first=True) 根据上表的理解：这个LSTM模型： input_size：每一次输入（即针对每一个数据点）接收数据张量最后一维应该为3，即输入XXX的大小应该为(∗,∗,3)(*,*,3)(∗,∗,3)； hidden_size： 隐藏层的向量大小为10，也就是说，对每一次输入的数据使用权重矩阵向第一个隐藏层映射，得到一个大小为(∗,∗,10)(*,*,10)(∗,∗,10)的张量，那么很容易理解，这里的权重矩阵WWW的大小应该为(3,10)(3,10)(3,10)； num_layers： 表示有几个隐藏层，目前理解LSTM中2个隐藏层的size大小是一样的，也就是说，如果隐藏层数设置为2，那么对应的两个隐藏层之间的权重矩阵大小就应该为(10,10)(10,10)(10,10)； batch_first：与输入XXX的前两个维度有关，之后在说明输入、输出格式的时候会提及它的影响。 有了以上的理解，那么就可以知道：符合这个模型的输入数据input_data张量的大小应该为(∗,∗,3)(*,*,3)(∗,∗,3)。 在进入模型输入输出说明前，借用web_2中的一张图片来进行预先展示，后续可以对照此图片理解。 模型输入 Pytorch给出的输入格式为： inputs: input, (h_0, c_0) input: shape(seq_len, batch, input_size) h_0: shape(num_layer*num_directions, batch, hidden_size) c_0: shape(num_layer*num_directions, batch, hidden_size) input的大小 input_size：为3，这是建立模型的时候决定的。对于一个句子翻译问题，一个数据点就是一个字，input_size=3就是说明打算用一个3维向量[a,b,c]来表示一个字； seq_len： 每个batch输入多少数据。比较难理解。换一个说法就是，每条数据包含多少个数据点。对于一个句子翻译问题，就是一个句子包括多少个字。这里需要注意的是，因为tensor都是齐整的，不像list中对于每一个子向量可以允许不同长度，甚至不同类型的子内容。这里的seq_len就规定了输入张量的句子长度大小。这明显很我们的需求不符：因为句子长度是变化的。因此在实际使用中需要使用torch的rnn中提供的三个函数来将不等长的输入转换为等长输入，这一部分内容会在后边讨论。 batch：表示有几个batch。对于一个句子翻译问题，就是一次性输入几个句子放到模型中做训练。 h_0和c_0的大小 num_directions：建立模型时没有设置bidirectional参数，默认为False，那么num_directions=1，即单向传播的隐藏层（正向）。如果bidirectional=True，就是双向隐藏层（正向+逆向）。需要注意的是，如果建立模型时num_layer&gt;1，在LSTM中隐藏层的叠加顺序是：（正向1-&gt;逆向1）-&gt; （正向2-&gt;逆向2）-&gt; ...。所以这也就解释了为什么h_0的大小有一个维度是num_layer*num_direction； batch：与模型构建相同，因为h_0和c_0是模型中间变量的初始值，所以对应于每一个batch，比如说每一个句子，都有对应的h_0和c_0，因为虽然权重WWW在各个时刻是共享的，但是因为句子输入不同，所以必然中间变量也必然不同。 hidden_size：与模型构建相同，这里不过多解释，具体可以看上图来理解。 c_0大小和h_0大小相同。这两个都是中间变量，具体的差异需要去学习LSTM内部模型细节，在此不再赘述。 至此，LSTM模型的输入就很直观了。 最后差一个batch_first参数的说明：可以看到，按照Pytorch给出的定义，input张量大小为(seq_len, batch, input_size)，而若在模型建立时设置batch_first=True，那么input张量的大小对应就应该为(batch, seq_len, input_size)。具体缘由与torch底层对LSTM做并行训练需求有关，不展开讨论了。 模型输出 Pytorch给出的输出格式为： outputs: output, (h_n, c_n) output: shape(seq_len, batch, num_directions*hidden_size) h_0: shape(num_layer*num_directions, batch, hidden_size) c_0: shape(num_layer*num_directions, batch, hidden_size) output的大小 output是最后一个隐藏层在所有时间点的输出，所以它的大小必然与输入的batch数量（句子数）和每个batch大小（句子长度）有关，也就是seq_len和batch，它们的含义已经在输入中说明了，此处不再赘述。需要注意的是最后一维：num_directions*hidden_size。可以看到如果不采用双向隐藏层，最后一维就是hidden_size，也就是模型构建中的参数值。如果使用双向，只不过就是输出了两层的变量而已。 h_n和c_n的大小 h_n和c_n实际上是由h_0和c_0在每个时间点上迭代获得的最终时刻的中间变量，所以它们的大小与h_0和c_0是一样的，在此也不再赘述。 最后是batch_first参数的说明：这个参数会影响输入input的大小，但却不会影响输出的大小。 处理不等长输入 待更新： torch.nn.utils.rnn.pad_sequence() torch.nn.utils.rnn.pack_padded_sequence() torch.nn.utils.rnn.pad_packed_sequence() Pytorch框架下多个模叠加 模型叠加 待更新： init forward tersor操作下的自动梯度 Seq2seq框架设计 待更新： 多对一（N2one） 多对多（N2N） 多对多（N2M） 自定义Dataloader ","link":"https://ChenChenGith.github.io/post/pytorch-lstm-xue-xi-xin-de/"},{"title":"【论文阅读】Rules of the road: Predicting driving behavior with a convolutional model of semantic interactions","content":"【来自Zoox公司】 摘要 解决实际复杂驾驶场景下的车辆未来状态预测问题。以往的研究是短时预测，没有充分利用3D感知数据和语义地图数据。这篇论文将语义信息使用统一的空间网格进行表征，从而可以使用深度卷积模型来融合场景信息。因此可以让对象和与其他对象及环境在每个时步进行交互。使用监督学习方法将未来的状态表征为分布。 上图：俯视图下的状态预测任务。红色框为预测对象，其未来轨迹真值为粉色线段。亮蓝色线段是最可能的预测轨迹，绿色线段是可能的其他轨迹。不确定性椭圆来描述最可能预测轨迹的不确定性。其他对象使用不同颜色渲染，包括洋红色的行人，蓝色的车辆和橘色的自行车。自车为绿色。速度单位向量使用橘色直线表迹，绿色线段是可能的其他轨迹。不确定性椭圆来描述最可能预测轨迹的不确定性。其他对象使用不同颜色渲染，包括洋红色的行人，蓝色的车辆和橘色的自行车。自车为绿色。速度单位向量使用橘色直线表示。环境中的其他语义信息使用不同的颜色展示，包括车道线、人行横道和停车线。 引言 自动系统的关键是预测其他智能体的未来状态，但是由于其他智能体的意图无法观测，所以需要根据当前和过去的信息生成一个似然分布。 当前有很多感知方面的研究，但是在轨迹预测方面的研究却很少，可能有两个原因：1）工业上更看重如何从原始感知数据中提取对象的表征，而对状态的优先级比较低；2）很少有用于状态预测的实车开发数据集，因为轨迹预测需要在实车数据进行开发才有意义，才能应对真实环境下的随机性。 本文介绍一个数据丰富的车辆轨迹预测数据集，包括9659量车和83880个预测场景，共计173小时，包括88个物理区域，并提供语义地图信息。采用俯视图的空间网格化语义地图编码环境历史数据，因此可以使用深度卷积网络结构来进行建模。 本文的另一个重要贡献是直接预测未来的分布，而不是单独的坐标点。对驾驶规划来讲，表征多模态的随机性很关键，必须考虑车辆的轨迹的可能性，衡量碰撞的风险。 研究了多个参数化和非参数化输出的分布表示，结果显示效果很好，最高能够预测未来5s的轨迹。 方法 包括三个部分： 一个新颖的交通实体及其环境的输入表示 一个神经网络，用于将历史和当前的环境表示映射至未来的行为 未来行为的几种可能的输出表示 输入表示：卷积网格 路网表示： 数据集包括车道、交叉口及其连接关系，其他相关属性包括人行横道、交通信号灯、停车线、让行线等。渲染为不同RGB颜色的网格图片。渲染后的道路信息张量表示为RRR，大小为W×H×3W\\times H\\times 3W×H×3。 交通实体表示： 假设有一个黑盒子模块能将传感器信息转换为3D追踪的实体。在每个时步，能够获得实体iii的2D坐标xitx_i^txit​、速度vitv_i^tvit​、加速度aita_i^tait​。同时也给出状态的不确定性估计，使用协方差范数将其引入道表示中∣∣∑i{x,v,a}t∣∣F||\\sum_{i\\{x,v,a\\}}^t||_F∣∣∑i{x,v,a}t​∣∣F​。 所有的维度都使用其99th99^th99th分位数进行了放缩，将其值限制在[−1,1][-1,1][−1,1]之内。每个实体的信息使用一个张量EitE_i^tEit​来表示，并将其对应到道路图张量RRR中此实体中心所在的坐标点处。 为了进行实体的交互建模，将除自车外的所有其他实体的放到同一个张量中E−it=∑j=iEjtE_{-i}^t=\\sum_{j\\not ={i}}E_j^tE−it​=∑j​=i​Ejt​。这些张量的大小为W×H×7W\\times H \\times 7W×H×7。（7=3+坐标+速度+加速度+不确定性） 其他动态信息： 将其他的场景信息表示为一个RGB图像DtD^tDt，大小为W×H×3W\\times H\\times 3W×H×3。包括所有实体的长方形有向框，并用颜色区分类别；交叉口处有信号灯的许可信息，分别使用不同颜色的交叉口连接线来表示。 时序模型： ttt时刻所有输入，以及目标实体iii通过串联的方式构建一个张量：Cit=[Eit,E−it,Dt,R]C_i^t=\\big[ E_i^t,E_{-i}^t,D^t,R\\big]Cit​=[Eit​,E−it​,Dt,R]，大小为W×H×20W\\times H \\times 20W×H×20，如下图所示。每个预测时刻，坐标圆心固定为目标实体的中心。 输出表示：不确定性和多模式建模 好的输出表示需要有以下特征： 每个时步，实体状态空间的概率分布表征：对于安全系统来说，离散点的估计是不够的 多峰，用来覆盖所有可能的交互多样性 一次性：处于效率考虑，不需要迭代递归就直接生成所有的轨迹 这个问题自然地被转换成一个序列到序列的生成问题。对于时刻ttt，观测到过去场景{X=Ct−l+1,Ct−l+2,...,Ct}\\{X=C_{t-l+1},C_{t-l+2},...,C_t\\}{X=Ct−l+1​,Ct−l+2​,...,Ct​}，预测未来的xyxyxy位置Y={(xt+1,yt+1),(xt+2,yt+2),...,(xt+m,yt+m))}Y=\\{(x_{t+1},y_{t+1}),(x_{t+2},y_{t+2}),...,(x_{t+m},y_{t+m}))\\}Y={(xt+1​,yt+1​),(xt+2​,yt+2​),...,(xt+m​,yt+m​))}。其中lll和mmm是过去和未来的观测时间长度。即预测策略为P(X∣Y)P(X|Y)P(X∣Y)，后续将使用多种方法来实现它。 考虑不确定性的参数回归输出 对未来每个时刻的位置(xt,yt)(x_t,y_t)(xt​,yt​)，预测一个二维高斯分布，均值为μt=(μx,t,μy,t)\\mu_t=(\\mu_{x,t},\\mu_{y,t})μt​=(μx,t​,μy,t​)，方差为σt=(σx,t,σy,t)\\sigma_t=( \\sigma_{x,t},\\sigma_{y,t})σt​=(σx,t​,σy,t​)，空间相关性标量ρt\\rho _tρt​。较之普通回归，这种方法获得的输出更好，而且能消除离群轨迹的影响。 训练的模型用于预测log标准差st=log⁡σts_t=\\log \\sigma _tst​=logσt​，使用最大似然估计来学习参数： log⁡P(X∣Y)=∑t′=t+1t+mlog⁡p(xt′,yt′∣μt′,st′,ρt′)\\log P(X|Y) =\\sum_{t^{&#x27;}=t+1}^{t+m} \\log p(x_{t^{&#x27;}},y_{t^{&#x27;}}|\\mu _{t^{&#x27;}},s_{t^{&#x27;}},\\rho _{t^{&#x27;}})logP(X∣Y)=∑t′=t+1t+m​logp(xt′​,yt′​∣μt′​,st′​,ρt′​) 其中ppp是二维高斯分布N(μt,σt,ρt)\\mathcal{N}(\\mu _t,\\sigma _t, \\rho _t)N(μt​,σt​,ρt​)的密度函数。 考虑不确定性的多模态回归 将上边的函数拓展到k个不同的高斯轨迹上，表示为(μi,s^i,ρi)(\\mu ^i,\\hat{s}^i,\\rho ^i)(μi,s^i,ρi)，权重为wiw _iwi​，则： P(X∣Y)=∑i=1kwiP(Y∣μi,s^i,ρi)P(X|Y)=\\sum_{i=1}^{k}w^i P(Y|\\mu ^i,\\hat{s}^i,\\rho ^i)P(X∣Y)=∑i=1k​wiP(Y∣μi,s^i,ρi)。 但是，这个模型有两个大问题：可交换性和模式坍塌： 可交换性：可以看到，输出对于排列是不变的，即{(μi,Si,ρi)}={μπ(i),sπ(i),ρπ(i)}\\{(\\mu ^i,S^i,\\rho ^i)\\}=\\{\\mu^{\\pi(i)},s^{\\pi(i)},\\rho ^{\\pi (i)}\\}{(μi,Si,ρi)}={μπ(i),sπ(i),ρπ(i)}，其中π\\piπ为某一种1,2,...,k{1,2,...,k}1,2,...,k的排列。 模式坍塌：以两个同方差分布为例，或Y∼12N(y1,σ2)+12N(y2,σ2)Y\\sim\\frac{1}{2}\\mathcal{N}(y^1,\\sigma ^2)+\\frac{1}{2}\\mathcal{N}(y^2,\\sigma ^2)Y∼21​N(y1,σ2)+21​N(y2,σ2)，如果y1y^1y1和y2y^2y2之间距离不是很远，特别是当∣y1−y2∣≤2σ|y^1-y^2|\\leq 2\\sigma∣y1−y2∣≤2σ时，那么这个混合模型ing就会给出一个均值为12(y1+y2)\\frac{1}{2}(y^1+y^2)21​(y1+y2)的单峰模型，约等于一个高斯模型N(12(y1+y2),σ2+12(y1+y2)2)\\mathcal{N}(\\frac{1}{2}(y^1+y^2),\\sigma ^2+\\frac{1}{2}(y^1+y^2)^2)N(21​(y1+y2),σ2+21​(y1+y2)2)。这会使得本来是kkk个高斯混合模型变成一个单峰且高方差的模型，也就是模式坍塌，无法很好的区分各个模型特征。 受到Latent Dirchlet Allocation(LDA)[1]启发，引入一个隐变量zzz，使得(μi,si,ρi)(\\mu ^i,s^i,\\rho ^i)(μi,si,ρi)以zzz为条件独立同分布： P(X∣Y)=∑i=1KP(zi∣X)P(Y∣μi,si,ρi,zi)P(X|Y)=\\sum_{i=1}^{K}P(z_i|X)P(Y|\\mu ^i,s^i,\\rho ^i,z_i)P(X∣Y)=∑i=1K​P(zi​∣X)P(Y∣μi,si,ρi,zi​) 其中，(μi,si,ρi)(\\mu ^i,s^i,\\rho ^i)(μi,si,ρi)时关于XXX和zzz的固定函数，解决可交换性问题。选择zzz为kkk维变量，鼓励在学习时输出一组不同的模式。（没有搞清楚如何解决的） 训练这个模型时，使用了条件变分自动编码器（CVAE）方法，将P(z∣X)P(z|X)P(z∣X)作为分类分布，使用带有重参数化技巧的Gumbell-Softmax分布[2]来对zzz进行采用和梯度反向传播。在我们的实验中P(z∣X)P(z|X)P(z∣X)就是高斯混合模型的权重，因此将我们的方法称之为GMM-CVAE。 非参数化输出分布 我们考虑另一种参数化形式，即使用网格地图作为输出。每个未来时刻都会输出一个网格图，每个网格的位置表示输出状态的概率。 【待续...】 D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. JMLR, 2003. ↩︎ https://spaces.ac.cn/archives/6705 ↩︎ ","link":"https://ChenChenGith.github.io/post/rules-of-the-road-predicting-driving-behavior-with-a-convolutional-model-of-semantic-interactions/"},{"title":"【论文阅读】MultiPath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction","content":"[来自Waymo LLC] 摘要 由于其他交通参与者的随机性，不可能获得下一时刻信息，因此必须考虑智能体未来轨迹的多种输出及对应的概率； 模型要求能够提供： 一组加权、简约的离散轨迹，涵盖可能的结果空间 对任何轨迹进行封闭式（closed-form）评估 两个属性对应两个问题： 多样性和覆盖率训练中模式崩溃（mode collapse） 可能的轨迹空间随时间指数增长，概率推断较难 所提出的MultiPath方法可以解决这个问题：包含有一个固定的轨迹锚点集合作为模型基础，从而分层考虑不确定性： 意图不确定性（intent uncertainty）用于衡量智能体想做什么（what），即考虑锚点轨迹集的分布 确定意图情况下，控制不确定性（control uncertainty）用于衡量智能体如何做到（how），即在每一预测步服从正态分布：均值对应与锚点的偏差，协方差对应单峰不确定性 最终的模型中，每一个预测时间步长（控制不确定性）做一个高斯混合模型，其中混合权重（表示意图不确定性分布）是固定的 这样就可以直接衡量任何未来轨迹的可能性，解决以往提供单一轨迹方法或无权重样本中的一些问题 有关安全的不确定性 处理近似误差（多少样本才能知道概率） 无法进行简单快速的概率推断（如在时空范围内计算期望） 方法 x\\rm xx：所有智能体历史轨迹和环境信息（如车道线、信号等状态等） s\\rm ss：未来轨迹，其的参数化分布为p(s∣x)p({\\rm\\textbf s}|{\\rm\\textbf x})p(s∣x) ttt：离散时间步 sts_tst​：未来轨迹序列 S=[s1,...,sT]S=[s_1,...,s_T]S=[s1​,...,sT​]：从t=1t=1t=1到固定时域TTT的未来轨迹 意图建模 KKK：轨迹锚点数 A={ak}k=1K\\mathcal{A}=\\{a^k\\}_{k=1}^KA={ak}k=1K​：锚点轨迹集合 ak=[a1k,...,aTk]{\\rm\\textbf a}^k=[a_{1}^k,...,a_{T}^k]ak=[a1k​,...,aTk​]：每个轨迹是一个状态序列（这里好像用s会更好） 使用sofmax分布描述离散不确定性：π(ak∣x)=expfk(x)Σiexpfi(x)\\pi({\\rm a}^k|{\\rm x})=\\frac{exp f_k({\\rm\\textbf x})}{\\Sigma_i exp f_i({\\rm\\textbf x})}π(ak∣x)=Σi​expfi​(x)expfk​(x)​ 控制不确定性 使用单峰假设，采用高斯分布： ϕ(stk∣ak,x)=N(stk∣atk+μtk(x),Σtk(x))\\phi({s_{t}^k}|{\\rm a}^k,{\\rm x})=\\mathcal N(s_{t}^k|a_{t}^k+\\mu_{t}^k({\\rm\\textbf x}),\\Sigma_{t}^k({\\rm\\textbf x}))ϕ(stk​∣ak,x)=N(stk​∣atk​+μtk​(x),Σtk​(x)) 其中，atk+μtka_{t}^k+\\mu_{t}^katk​+μtk​是均值参数，μtk\\mu_{t}^kμtk​表示从锚点状态atka_{t}^katk​处偏离的值，可以视为先验锚点分布的残差，即考虑道路线形等外部条件下的一种特例模型 Σtk\\Sigma_{t}^kΣtk​是方差参数，也是关于x\\rm xx的函数 总体状态空间分布 p(s∣x)=∑k=1Kπ(ak∣x)∏t=1Tϕ(st∣ak,x)p({\\rm\\textbf s}|{\\rm\\textbf x})=\\sum_{k=1}^K\\pi({\\rm\\textbf a}^k|{\\rm\\textbf x})\\prod_{t=1}^T\\phi(s_t|{\\rm\\textbf a}^k,{\\rm\\textbf x})p(s∣x)=∑k=1K​π(ak∣x)∏t=1T​ϕ(st​∣ak,x) 上式是一种高斯混合模型分布，其中混合权重不随时间变化 这是对两种类型的不确定性建模的自然选择:它具有丰富的代表性，一个封闭的配分函数，而且紧凑 获得锚点轨迹A\\mathcal AA 使用k-means 方法获得A\\mathcal AA的先验分布，距离算法采用d(u,v)=ΣtT∣∣Muut−Mvvt∣∣22d({\\rm\\textbf u},{\\rm\\textbf v})=\\Sigma_t^T||M_u{\\rm\\textbf u}_t-M_v{\\rm\\textbf v}_t||_2^2d(u,v)=ΣtT​∣∣Mu​ut​−Mv​vt​∣∣22​。其中MuM_uMu​和MvM_vMv​是放射变换矩阵，用于将轨迹转换为以规范旋转和平移不变的主体为中心的坐标框架 ###学习 通过模仿学习来训练模型，方法是拟合参数以最大化轨迹数据的似然函数 数据集为{(xm,s^m)}m=1M\\{({\\rm\\textbf x}^m,{\\hat{\\rm\\textbf s}^m})\\}_{m=1}^M{(xm,s^m)}m=1M​ 以θ\\thetaθ为权重参数，使用深度神经网络求解预测分布参数：π(ak∣x)\\pi({\\rm\\textbf a}_k|{\\rm\\textbf x})π(ak​∣x)、μ(x)tk\\mu({\\rm\\textbf x})_t^kμ(x)tk​和Σ(x)tk\\Sigma({\\rm\\textbf x})_t^kΣ(x)tk​ 负对数似然loss为：l(θ)=−∑m=1M∑k=1K1(k=k^m)[logπ(ak∣xm;θ)+∑t=1TlogN(stk∣atk+μtk,Σtk;)xm;θ]l(\\theta)=-\\sum_{m=1}^M\\sum_{k=1}^K\\mathbb {1}(k=\\hat{k}^m){\\big [}{\\rm log}\\pi({\\rm\\textbf a}^k|{\\rm\\textbf x}^m;\\theta)+{\\sum_{t=1}^T{\\rm log}{\\mathcal N}(s_t^k|a_t^k+\\mu_t^k,\\Sigma_t^k;)} {\\rm\\textbf x}^m;\\theta{\\big ]}l(θ)=−∑m=1M​∑k=1K​1(k=k^m)[logπ(ak∣xm;θ)+∑t=1T​logN(stk​∣atk​+μtk​,Σtk​;)xm;θ] 这是一个时间序列展开的标准GMM似然估计 其中，1(⋅)\\mathbb 1(\\cdot)1(⋅)是指示函数，k^m\\hat{k}^mk^m为距离实际轨迹点s^m{\\hat{\\rm\\textbf s}^m}s^m最近锚点的索引，是通过l2\\mathcal l^2l2范数距离计算的 轨迹加权 直接学习损失函数，不需要进行重要性采样（importance sampling） 实际上π(ak∣x)\\pi({\\rm\\textbf a}_k|{\\rm\\textbf x})π(ak​∣x)可以仍未是重要性采样 输入 x\\rm\\textbf xx：使用一个3维数组表示，前两维为空间坐标，最后一维为以往实步的动静态信息 观测输入：定向边界的二进制图，每一时步为一个通道 其他动态信息：包括信号灯状态和道路信息使用额外通道 神经网络设置 分为两步 第一步是完全卷积的网络，来保留空间结构，输入为一个3D表示，输出为3D特征图 第二部是提取11*11的块，中心就是智能体的中心，并通过旋转来转到智能体自身坐标系 实验 方法 包括本文的MultiPath、Regression、Min-of-K、CVAE、Linear 指标 因为各个模型的输出不同，有的是单一轨迹结果、有的是分布、有的是网格的占用概率 提出两个指标： 对数似然：log p(s^k∣x){\\rm log} \\ p(\\hat{\\rm\\textbf s}_k|{\\rm\\textbf x})log p(s^k​∣x) 距离：average displacement error：1TΣt=1T∣∣s^t−st∗∣∣2\\dfrac{1}{T} \\Sigma_{t=1}^T||{\\hat s_t}-{s_t^*}||_2T1​Σt=1T​∣∣s^t​−st∗​∣∣2​和Final displacement error:∣∣s^T−sT∗∣∣||{\\hat s_T}-{s_T^*}||∣∣s^T​−sT∗​∣∣ 玩具实验-3向交叉 意图不确定性分布为{0.3,0.5,0.2}\\{0.3,0.5,0.2\\}{0.3,0.5,0.2} 控制不确定性分使用sin函数：y=sin(ωt+ϕ)y=sin(\\omega t+\\phi)y=sin(ωt+ϕ)，其中ω∼u(0,2),ϕ∼u(−π,π)\\omega \\sim u(0,2),\\phi \\sim u(-\\pi,\\pi)ω∼u(0,2),ϕ∼u(−π,π) ###自动驾驶行为预测 * ","link":"https://ChenChenGith.github.io/post/multipath-multiple-probabilistic-anchor-trajectory-hypotheses-for-behavior-prediction/"},{"title":"高斯混合模型","content":"高斯模型也叫正态分布，是常用的一种变量分布模型。 单高斯模型[1] 二维高斯分布的概率密度函数为： f(x)=12πσexp(−(x−μ)22σ2)f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})f(x)=2πσ​1​exp(−2σ2(x−μ)2​) 其中， μ\\muμ为高斯分布的均值 σ2\\sigma^2σ2为高斯分布的方差 在python中生成符合高斯分布的二维坐标点数据 import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm import seaborn as sns plt.style.use('seaborn') # 生成3组不同均值和方差的二维坐标数据 # 每组数据的x、y的均值在mean_set中，方差在var_set中，生成的数据点个数在num_set中 mean_set = [[-0.8, 0.2], [4.5, 3], [10, 2.5]] var_set = [[0.5, 1], [1, 1], [4, 1]] num_set = [400, 600, 1000] mean_1, var_1, num_1 = mean_set[0], var_set[0], num_set[0] data_1 = np.random.multivariate_normal(mean_1, np.diag(var_1), num_1) mean_2, var_2, num_2 = mean_set[1], var_set[1], num_set[1] data_2 = np.random.multivariate_normal(mean_2, np.diag(var_2), num_2) mean_3, var_3, num_3 = mean_set[2], var_set[2], num_set[2] data_3 = np.random.multivariate_normal(mean_3, np.diag(var_3), num_3) # 绘制二维图 fig, ax1 = plt.subplots(figsize=(10, 8)) plt.scatter(data_1[:, 0], data_1[:, 1], s=2, color=&quot;blue&quot;) plt.scatter(data_2[:, 0], data_2[:, 1], s=2, color=&quot;green&quot;) plt.scatter(data_3[:, 0], data_3[:, 1], s=2, color=&quot;red&quot;) # 绘制分布概率密度图（x轴） ax2 = ax1.twinx() sns.distplot(data_1[:, 0],hist=False, color=&quot;blue&quot;) sns.distplot(data_2[:, 0],hist=False, color=&quot;green&quot;) sns.distplot(data_3[:, 0],hist=False, color=&quot;red&quot;) plt.show() 混合高斯模型 上述代码建立了三组来自不同高斯分布的二维坐标数据，使用一个高斯模型无法描述，因此需要引入高斯混合模型。高斯混合模型可以看作是由KKK个单高斯模型组合而成的模型，这K个子模型是混合模型的隐变量。高斯混合模型的概率分布如下： P(x)=∑k=1KαkN(μk,Σk)P(x)=\\sum^K_{k=1}\\alpha_kN(\\mu_k,\\Sigma_k)P(x)=∑k=1K​αk​N(μk​,Σk​) 其中， KKK是高斯混合模型中的单高斯模型个数 αk\\alpha_kαk​是混合权重，满足0⩽αk⩽1,∑k=1K=10\\leqslant\\alpha_k\\leqslant 1, \\sum^K_{k=1}=10⩽αk​⩽1,∑k=1K​=1 N(μk,Σk)N(\\mu_k,\\Sigma_k)N(μk​,Σk​)是第kkk个单高斯模型的分布 ","link":"https://ChenChenGith.github.io/post/hun-he-gao-si-mo-xing/"},{"title":"【生活随笔】基金啊基金","content":"上周六李老师又看了一遍基金。唉，提出了一些问题，改了两天，越改越迷茫：到底啥是科学问题？写到什么程度才算把科学问题写透了？ 越来越没有信心了，之前应该是想的比较清楚了的，但是还是不够清楚，也许我不能这么想，就是因为没有做，所以不够清楚，这是必然的。明天再改吧，换换脑子。 到底能不能做出东西来？这也是另外一个很焦虑的问题，也许我真的是太着急了。 路上和文宇说：科研就像打比赛一样，赢得越多与有信心，气势如虹，一路向前。如果一开始就很多次失败，真的是很难再打回去了。虽然说，不要害怕失败，要坚持，但一次次的负反馈要有多大的坚毅才能不动摇呢？ ","link":"https://ChenChenGith.github.io/post/sheng-huo-sui-bi-ji-jin-a-ji-jin/"},{"title":"【科研随笔】基金写作心得","content":"【施工中...】 年前在写本子，年后又大改本子。在写和改的过程中，有一些心得总结一下。 引言：直面问题 不论是基金还是论文，逻辑很重要。但一般来说，逻辑不能太绕，一是太绕了，会显得啰嗦，反而淹没了想要讲的核心问题；二是面对同领域的专家学者，很多道理不用多讲，其实最关注的也还是你的核心问题。 这次写本子一开始就像写学位论文一样，逻辑是这样的： 自动驾驶重要性（一段） 驾驶安全重要性（一段） 风险评估与自动驾驶决策（一句）+ 风险评估重要性（一段） 风险评估问题（一段） 综上... 可以看到，当说到问题的时候，已经是一页之后了，别人一眼看不到你的科学问题，就会迟迟进入不了阅读状态，所以说引言一定是要直面问题的。更改之后现状变成这样： 自动驾驶重要性（宏观一段） 风险评估重要性（一句）+ 风险评估问题（与上句同一段） 综上... 专家阅读的时候就会：第一段很快过，第二段首先把握了具体方向，接着马上就是具体问题解析，然后最后一段说明要做什么，很清晰，不绕，直接陈述就是最好的表达。 文献综述：直达本质 关于文献的描述 其实我一直认为我的文献综述水平是不行的，包括博士论文中的文献综述，有拼凑嫌疑。 文献综述应该是对现有文献思路、脉络的一个总结，简单一点来讲，就是把文献聚类，可以按照时间、方法等维度。看似简单，但也很容易写不清楚。这次写作李老师提了一个关键点：就是到底现在这些研究，在本质上是什么不同；这种不同就会分为几类；那么你的工作，是属于哪个类别，这样才能总结出本质问题。 以轨迹预测举例，第一版本是这么写的： 当前研究根据方法可以分为三类：基于物理约束的预测、基于行为意图的预测、基于学习的预测 每一类bala bala.... 这样也不是不可以，但就会让人很迷惑：这几种方法到底有啥差别？优劣是什么？第一时间看不出来。之后修改为： 轨迹预测基本任务是根据环境信息判断未来可能坐标点序列，当前研究根据对环境信息的使用程度，可分为三类：基于单车信息的递推、考虑道路拓扑的预测、考虑道路拓扑及周车交互的预测 每一类bala bala... 实际上，改了之后的三类和第一版本的三类是一样的，但就能直接指出到底差别在哪里，以及我的研究是在哪个层面上做的。 关于研究现状总结 一般来讲，文献综述的总结会对应到整个本子要解决的几个问题上，也是为了后边的研究内容做衔接和准备。但在本次的基金撰写中，最后发现如果硬要在某个点上总结出一条不足来，有点勉强，因为在另一点的综述也会涉及到相关的内容。最后就需要做进一步的总结，而不能硬是把每个综述的点就要对应某个问题。 ","link":"https://ChenChenGith.github.io/post/ke-yan-sui-bi-ji-jin-xie-zuo-xin-de/"},{"title":"【生活随笔】博后半年小结","content":"来到清华已经过去了半年，本来应该是在春节前总结最为合适，但因为一直忙着写基金本子，一直拖到了年后来。 如果用几个关键词来总结这半年的感觉，应该是：激动，习惯，挣扎。 0️⃣激动的新奇 “清华大学，这是清华大学”，没错，这是在开始的一个月心里最多的想法。我是从来没有一天能想到我与清华之间能有什么关系：除了大二的时候参加大物竞赛来清华参加过一次考试。毕竟是国内的第一学府，即使是在博后面试的时候，我也不抱太大希望，这可是清华！但在我真的从深圳又再一次回到北京的时候，特别是站在清华大学门口的时候，激动是真的，不论以后会如何，至少我来到过了某个全国的顶峰。 1️⃣开始的打击 从原来的交通运输到车辆运载，起始算是换了方向的，而且是从一个较“软”的学科换到了一个比较“硬”的学科。所以从一开始就心里压力就比较大，因为不知道能不能做的好。事实也证明，在刚刚开始的3个月，每次开组会我都很懵：组会PPT上讲的内容都是算法、公式，还没有什么注释，很硬核。这在之前的学生生涯中基本没有见到过，而且组里的学生和老师还讨论的很热烈，仿佛可以把公式转化成文字一样，可以想象到我是多么的迷惑，不知所措，就像刘姥姥进了大观园。也可以想象到心里是会受多大的打击：这就是我未来可能要接触的东西？我能不能在有限的时间内学会？是真的越来越没有信心了。 2️⃣新的科研逻辑 其实到现在我也不能断言这是学校之间的差别，还是学科之间的差别，也可能是两者兼有。 从学生角度，之前的逻辑是保研，最好能直博，然后按时毕业，大家恨不得赶快拿到博士学位就出去工作。但这边的话反而直博是次优选择：大家都是以通过硕士阶段作为跳板，然后申请国外更好大学的博士。博士也不急着毕业，发一发论文，有一些成果之后，申请更好学校的博后，然后再回到清华或者其他学校开展工作。完全不同的境况导致完全不同的逻辑，不亲眼来看看，是无法想象到的。 从科研角度，更强调科学性了。当然，这大部分原因是因为学科不同，这边是真的“硬”，直达问题本质，相对而言，交通运输可能更偏向于管理，管理一旦与人打交道，就有很多不可控的因素了。这引起的另外一个不同就是科研和项目的拆分，研究问题就是研究问题，项目就仅仅是项目，将研究问题套一个应用的壳子就完成项目就好了，这是到底技术主导、还是项目主导的问题了。交通运输没有什么硬技术，所以就要靠项目来拿数据、拿应用，否则很多方法提出来，也没有办法验证。 3️⃣慢慢的习惯 刚入站的时候，感觉很紧迫，两年时间，要发至少发两篇论文，计算着时间，很着急。但是现在也知道，着急不来——除非水论文，但我又不想水。开始慢慢学习机器学习、强化学习的一些方法，开组会看ppt也开始能看懂了，至少知道解决了什么问题，什么逻辑，什么方法。虽然还没有到能提出质疑的地方，至少组会也能有所收获了。 半年最大的工作成果就是完成了自动驾驶仿真软件中安全性评价模块的开发，仔细来讲，绝对算不上是一项科研内容，但至少是一项工作。还有就是投了一个安全评价的专利，也指望不上什么，少则3年，多则4年才能完全授权。 还有就是项目方面，算是负责两个项目，但实际上也只是帮忙把控一下进展，具体的事情还是由学生来做的。 4️⃣基金的挣扎 每年的寒假都是写基金的时候，既然投身到了学术界，就不可避免。年前憋了一个月，终于算是憋出了一个格式完整的本子来。给了赵老师看，李老师看，都反应没写透。两位老师都说，写本子是要50%做过的东西，加上50%要做的东西，这样才能知道哪些科学问题是要确实解决的，到底要怎么做。我也很认同，但确实还做不到。从博士的驾驶行为安全到车辆的行驶安全，看似类似，但是对象、方法、目标、数据支持都变了，其实就是换方向了。李老师说，要坚持到一个点上不动摇，但实际上我实际上已经换了方向了。所以写本子就很挣扎：我知道写的不好，但我也不知道怎么才能写得好。就仿佛我和目标之间有一层纱，我大概能看到它长什么样，但我不知道要怎么才能拂开这层纱。写本子也是一样，只能写到大概要做啥，但是具体的技术难点、解决办法很虚浮。 不过也是有收获的。确实，写本子是很考验水平的事情，我现在还没有什么水平，但是至少也通过写本子，把要做的事情明确了一层，至少接下来的一年，我知道要做什么事情，达成什么效果了。所以再难，本子也要写。 5️⃣未来的展望 本来2年的时间很紧张，去掉适应和找工作各半年，就剩下一年了。但现在看来，做满二站四年也不是没有可能，还是想做出一些东西来的。至少接下来的一年，知道要做什么，就好好做就好了，希望能有一些成果出来。 加油！ ","link":"https://ChenChenGith.github.io/post/sheng-huo-sui-bi-jian-nan-de-chu-jing/"},{"title":"【未完成】自动驾驶数据集-Argoverse Dataset-Map&Forecasting-简介","content":"Argoverse数据集是由Argo AI、卡内基梅隆大学、佐治亚理工学院发布的用于支持自动驾驶汽车3D Tracking和Motion Forecasting研究的数据集。本篇博客主要对其中的HD Map和Motion Forecasting 数据集进行简介。 数据集地址 API接口 CVPR 2019论文 数据采集 Argoverse数据集均由Argo AI公司的自动驾驶测试车采集，主要包括两个城市：迈阿密（MIA）和匹兹堡（PIT）。迈阿密包覆盖204Km道路，匹兹堡覆盖86Km道路。 数据采集设备包括： 2个VLP-32激光雷达，检测范围200m 7个高分辨率（1920*1200）环形摄像头，30Hz，提供360度视野 2个前向立体相机，分辨率2056*2464，5Hz 6自由度定位数据 地图 Argoverse数据集包含由3个地图： 矢量地图，由车道中心线和相关属性组成 栅格化地图，包括地面高度信息 栅格化地图，包括可行驶区域和兴趣点区域 矢量地图基本组成是车道段，每个车道段都只有一个行进方向。每个车道段属性包括： ID 是否有交通信号控制 转向方向（左、右、无） 是否未遇交叉口内 左侧的车道ID 右侧的车道ID 下一车道段的ID 上一车道段的ID 中心线坐标 车道宽度：MIA为3.84m±0.89m3.84m \\pm 0.89m3.84m±0.89m，PIT为3.97m±1.04m3.97m \\pm 1.04m3.97m±1.04m 轨迹预测Baseline 算法 数据集中尽可能地排除了一些匀速运动或者静止的场景，主要包括1）交叉口处，2）左转或右转，3）换道和4）密集交通流下的场景。 坐标和标准化 有三种坐标： 原始轨迹数据的坐标系为城市坐标系 模型中以车道中线为参考，定义了一个2D的曲线坐标系统，包括距离中心线的切线距离和垂向距离 map-free模型中，将所有的信息都规整为：以原点开始，以xxx轴正向的某个点结束（即yT=0y^T=0yT=0）（没看懂） 特征工程 对于轨迹ViV_iVi​，定义ttt时刻的social和spatial context： 对于social contex (sits^t_isit​)，包括距离前、后对象的最小距离，以及对象数量 对于spatial context (mitm^t_imit​)，将轨迹坐标转换为车道段坐标系下的坐标 预测算法 两个算法：KNN和LSTM。 代码解析 Baseline代码地址 特征计算(compute_features.py) 1. arse_arguments : (Method) 获取运行参数，包括： --data_dir：原始数据csv文件所在文件夹路径 --feature_dir：处理后的特征数据存储文件夹路径 --mode：模式，仅能选择train/val/test --batch_size：并行计算的batch数 --obs_len：轨迹的可观测长度，int --pred_len：预测长度，int -small：是否使用小数据集，bool （没看懂） 2. compute_features : (Method) 计算social和spacial feature的主要函数，主要步骤包括： df = pd.read_csv(dir) # 读入数据 agent_track = df[...] # agent车辆轨迹数据 # 提取social features social_features_utils_instance.compute_social_features( df, # 总数据 agent_track, # agent车辆轨迹数据 args.obs_len, # 观测长度 args.obs_len + args.pred_len, # 总长度 RAW_DATA_FORMAT # 关于df表头的关键字字典 ) map_features, map_feature_helpers = map_features_utils_instance.compute_map_features( agent_track, args.obs_len, args.obs_len + args.pred_len, RAW_DATA_FORMAT, args.mode, ) To compute_social_features; To compute_map_features 工具对象 Social feature计算(social_features_utils.py) 1. compute_social_features df_obs = df[len&lt;obs_len] # 定义可观测总数据 agent_track_obs = agent_track[len&lt;obs_len] # 可观测agent数据 # 提取相关的其他轨迹数据 social_tracks_obs = filter_tracks( df_obs, obs_len, RAW_DATA_FORMAT # 关于df表头的关键字字典 ) # 获取各个时刻前后最近距离 # [[min_front_0, min_back_0], # [min_front_1, min_back_1], # ..., # [min_front_T, min_back_T]] min_distance_front_and_back_obs = self.get_min_distance_front_and_back( agent_track_obs, social_tracks_obs, obs_len, RAW_DATA_FORMAT, viz=False ) # 获取附近对象的数量，1列数据 num_neighbors_obs = self.get_num_neighbors(agent_track_obs, social_tracks_obs, obs_len, raw_data_format) # 合并前后距离和数量，一共变成3列 social_features_obs = np.concatenate( (min_distance_front_and_back_obs, num_neighbors_obs), axis=1) # 规整一个与agent数据长度相同的空集赋值，预测时域内各个特征默认为None return social_features[:obs_len] = social_features_obs Back to compute_features To filter_tracks; To get_min_distance_front_and_back; To get_num_neighbors 2. filter_tracks 过滤提取相关轨迹数据。 df_groups = df_obs.groupby(&quot;TRACK_ID&quot;) for group_name, group_data in group： # 循环每个group： ... # 数据不足EXIST_THRESHOLD=15个的跳过 ... # 自车跳过 if get_is_track_stationary(group_data): continue # 静止车辆跳过 # 补全缺失的轨迹数据 padded_track = pad_track( group_data, seq_timestamps, # 时间戳集合=np.unique(df_obs[&quot;TIMESTAMP&quot;].values) obs_len, RAW_DATA_FORMAT ) social_tracks.append(padded_track) # 添加到列表 return social_tracks Back to compute_social_features To get_is_track_stationary ；To pad_track 3. get_is_track_stationary 检查轨迹是否为静止车辆。（个人感觉这样的判定有点没有道理） vel = compute_velocity(group_data) # 计算速度 # 第STATIONARY_THRESHOLD=13个数据点的速度小于VELOCITY_THRESHOLD=1，认为是静止 return True if vel[STATIONARY_THRESHOLD] &lt; VELOCITY_THRESHOLD else False Back to filter_tracks To compute_velocity 4. compute_velocity 计算速度。 ['X' or 'Y'].diff()/['TIMESTAMP'].diff() return vel = sqrt('X'**2 + 'Y'**2) # shape(obs_len-1, 1) Back to get_is_track_stationary 5. pad_track 补全缺失数据。 # 比较df_obs中时间戳set与当前轨迹的时间戳set，获得pad的起点和终点 start_idx end_idx # 使用np.pad命令，用边缘填充start_idx之前和end_idx之后的数据 padded_track_array = np.pad(group_data, ((start_idx, obs_len - end_idx - 1)),(0, 0), 'edge') # 处理离开又进入的情况，即中间段缺失数据 padded_track_array = fill_track_lost_in_middle( padded_track_array, seq_timestamps, # df_obs的时间戳，全集 RAW_DATA_FORMAT ) Back to filter_tracks To fill_track_lost_in_middle 6. fill_track_lost_in_middle 处理离开又进入的情况，即中间段缺失数据。 # 循环方式，逐行匹配时间戳，如果不存在，就使用上一行来填充 i = 0 for timestamp in seq_timestamps: filled_track[0] = track_array(i) if timestamp in track_array['TIMESTAMP']: i += 1 Back to pad_track 7. get_min_distance_front_and_back 获取自车前后对象的最小距离。 # 新建保存变量，两列分别表示前后距离，DEFAULT_MIN_DIST_FRONT_AND_BACK=100 min_distance_front_and_back = np.full((obs_len, 2), DEFAULT_MIN_DIST_FRONT_AND_BACK) for i in range(obs_len): # 循环每个时刻 for social_track in social_tracks[:, i, :]: # 各个时刻下所有周车的数据 instant_distance = sqrt((agent_x - neigh_x)**2 + (agent_y - neigh_y)**2) # 计算各个周车的距离 # 如果距离大于NEARBY_DISTANCE_THRESHOLD=50米，continue if instant_distance &gt; self.NEARBY_DISTANCE_THRESHOLD: continue # 检查是在前还是在后 is_front_or_back = self.get_is_front_or_back( agent_track[:2, :] if i == 0 else agent_track[:i + 1, :], neigh_x, neigh_y, RAW_DATA_FORMAT, ) # 根据前后来更新 if &quot;front&quot;: min_distance_front_and_back[i, 0] = min( min_distance_front_and_back[i, 0], instant_distance) if &quot;back&quot;: min_distance_front_and_back[i, 1] = min( min_distance_front_and_back[i, 1], instant_distance) return min_distance_front_and_back Back to compute_social_features To get_is_front_or_back 8. get_is_front_or_back 检查车辆是在前还是在后。 采用从后向前寻找agent_track上两个不同的点，确定车辆朝向，然后计算neigh_x和neigh_y与两个点之间距离，判断距离大小来确定是前还是后。 Back to get_min_distance_front_and_back 9. get_num_neighbors 获取附近的对象数量。 for i in range(obs_len): # 循环每个时刻 for social_track in social_tracks[:, i, :]: # 各个时刻下所有周车的数据 # 提取对应时刻各个周车坐标，计算距离 instant_distance = np.sqrt((agent_x - neigh_x)**2 + (agent_y - neigh_y)**2) # 如果距离小于NEARBY_DISTANCE_THRESHOLD=50，计数 if instant_distance &lt; self.NEARBY_DISTANCE_THRESHOLD: num_neighbors[i, 0] += 1 return num_neighbors Back to compute_social_features Map feature计算(map_features_utils.py) 1. compute_map_features Back to compute_features ","link":"https://ChenChenGith.github.io/post/zi-dong-jia-shi-shu-ju-ji-argoverse-dataset-mapandforecasting/"},{"title":"Hello World","content":"Hello World！x=Σi=1N(ZγV(s))\\textbf{x}=\\Sigma_{i=1}^{N}(\\mathcal{Z} \\gamma V(s))x=Σi=1N​(ZγV(s)) ≠\\neq​= ∫12和∑21\\int_{1}^{2}和\\sum_{2}^{1}∫12​和∑21​ 标题1 二级 三级 标题2 2二级 2三级 用于测试的一个开始 ","link":"https://ChenChenGith.github.io/post/hello-world/"}]}